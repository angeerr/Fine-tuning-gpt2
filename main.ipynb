{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-13T03:07:23.197932Z",
     "iopub.status.busy": "2023-11-13T03:07:23.197387Z",
     "iopub.status.idle": "2023-11-13T03:09:26.032471Z",
     "shell.execute_reply": "2023-11-13T03:09:26.031228Z",
     "shell.execute_reply.started": "2023-11-13T03:07:23.1979Z"
    },
    "id": "eZU34Qn9MREJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0dd7a214-9ed3-4cec-872c-5fbbb806e54f",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-04T07:22:50.101142100Z",
     "start_time": "2023-12-04T07:21:17.373609200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: cannot stat `/kaggle/input/main-code': No such file or directory\n",
      "cp: cannot stat `/kaggle/input/finetuning-dataset/src/*': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[WinError 3] 系统找不到指定的路径。: '/kaggle/working/src'\n",
      "C:\\Users\\14045\\Desktop\\machine learning group\\MDS5210-23fall\n",
      "dataset-metadata-template.json\n",
      "dataset-metadata.json\n",
      "Kaggle_training.md\n",
      "kernel-metadata-template.json\n",
      "kernel-metadata.json\n",
      "kernel.json\n",
      "latest_code\n",
      "main.ipynb\n",
      "README.md\n",
      "src\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure you have added the dataset into the notebook\n",
    "# Move the code to working directory\n",
    "!cp -r /kaggle/input/main-code /kaggle/working/src\n",
    "\n",
    "# Move the dataset to working directory\n",
    "!cp -r /kaggle/input/finetuning-dataset/src/* /kaggle/working/src\n",
    "\n",
    "# install necessary packages, as Kaggle will clear installed packages when restart the kernel.\n",
    "%pip install -r src/requirements.txt\n",
    "\n",
    "%cd /kaggle/working/src\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model_pretrained = GPT2LMHeadModel.from_pretrained(pretrained_model_name_or_path=r\"D:\\models\\355M\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T03:00:31.021129Z",
     "start_time": "2023-12-01T03:00:26.538586500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EYLSFTStaticDataset' from 'dataset' (D:\\anaconda3\\Lib\\site-packages\\dataset\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EYLSFTStaticDataset\n\u001B[0;32m      2\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m EYLSFTStaticDataset(block_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m,\n\u001B[0;32m      3\u001B[0m                                    split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m                                    max_examples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m      5\u001B[0m                                    tokenizer_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtiktoken/gpt2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'EYLSFTStaticDataset' from 'dataset' (D:\\anaconda3\\Lib\\site-packages\\dataset\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from dataset import EYLSFTStaticDataset\n",
    "train_ds = EYLSFTStaticDataset(block_size=1024,\n",
    "                                   split='train',\n",
    "                                   max_examples=None,\n",
    "                                   tokenizer_name=\"tiktoken/gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T03:01:22.989814Z",
     "start_time": "2023-12-01T03:01:21.895586900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:17:13.48035Z",
     "iopub.status.busy": "2023-11-13T03:17:13.47988Z",
     "iopub.status.idle": "2023-11-13T03:18:49.078171Z",
     "shell.execute_reply": "2023-11-13T03:18:49.076972Z",
     "shell.execute_reply.started": "2023-11-13T03:17:13.480309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Make sure you turn on the GPU when running the script\n",
    "# TODO: Change this line to the script you want to execute\n",
    "# !python <script_name.py> \n",
    "\n",
    "# e.g. \n",
    "!python train_sft.py --exp-name sft_experiment --batch-size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(pretrain, batch_size, exp_name):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    cfg = get_configs(\"gpt2-medium\") # change this line to select different models\n",
    "    cfg.max_steps = 200000 // batch_size\n",
    "    cfg.batch_size = batch_size\n",
    "    cfg.pretrain = pretrain\n",
    "    assert pretrain == \"huggingface\" # make sure the pretrained model is in the format of huggingface.\n",
    "    cfg.exp_name = exp_name\n",
    "\n",
    "    # load the pretrained GPT model based on the configuration\n",
    "    model = GPT.from_pretrained(cfg)\n",
    "    \n",
    "    # load SFT dataset\n",
    "    train_ds = EYLSFTStaticDataset(block_size=1024,\n",
    "                                   split='train',\n",
    "                                   max_examples=None,\n",
    "                                   tokenizer_name=\"tiktoken/gpt2\")\n",
    "    test_ds = EYLSFTStaticDataset(block_size=1024,\n",
    "                                  split='test',\n",
    "                                  max_examples=None,\n",
    "                                  tokenizer_name=\"tiktoken/gpt2\")\n",
    "    \n",
    "    trainer = SFTTrainer(cfg, device, model, train_ds, test_ds)\n",
    "    trainer.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "def main(pretrain, batch_size, exp_name):\n",
    "    torch.manual_seed(1234)\n",
    "    train(pretrain, batch_size, exp_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from configs import get_configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = get_configs(\"gpt2-medium\") # change this line to select different models\n",
    "cfg.max_steps = 200000 // batch_size\n",
    "cfg.batch_size = batch_size\n",
    "cfg.pretrain = pretrain\n",
    "assert pretrain == \"huggingface\" # make sure the pretrained model is in the format of huggingface.\n",
    "cfg.exp_name = exp_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel \n",
    "model_pretrained = GPT2LMHeadModel.from_pretrained(cfg.hf_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trainers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mclick\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrainers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SFTTrainer\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgpt\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GPT\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EYLSFTStaticDataset\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'trainers'"
     ]
    }
   ],
   "source": [
    "import click\n",
    "import torch\n",
    "from trainers import SFTTrainer\n",
    "from gpt import GPT\n",
    "from dataset import EYLSFTStaticDataset\n",
    "from configs import get_configs\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Avoid GPU version conflict (For Kaggle GPU only). Comment below two lines if you use local machine in order to speed up training.\n",
    "import torch._dynamo.config\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "\n",
    "def train(pretrain, batch_size, exp_name):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    cfg = get_configs(\"gpt2-medium\") # change this line to select different models\n",
    "    cfg.max_steps = 200000 // batch_size\n",
    "    cfg.batch_size = batch_size\n",
    "    cfg.pretrain = pretrain\n",
    "    assert pretrain == \"huggingface\" # make sure the pretrained model is in the format of huggingface.\n",
    "    cfg.exp_name = exp_name\n",
    "\n",
    "    # load the pretrained GPT model based on the configuration\n",
    "    model = GPT.from_pretrained(cfg)\n",
    "    \n",
    "    # load SFT dataset\n",
    "    train_ds = EYLSFTStaticDataset(block_size=1024,\n",
    "                                   split='train',\n",
    "                                   max_examples=None,\n",
    "                                   tokenizer_name=\"tiktoken/gpt2\")\n",
    "    #train_size = int(0.8 * train_ds.__len__())  # use 80% data in train_dataset as train dataset\n",
    "\n",
    "    # compute the size of validation set\n",
    "    #val_size = train_ds.__len__() - train_size  # use 20% data in train_dataset as validation dataset\n",
    "    #print(train_size, val_size, train_ds.__len__())\n",
    "    # use random_split to split train dataset and validation dataset\n",
    "    #train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "    test_ds = EYLSFTStaticDataset(block_size=1024,\n",
    "                                  split='test',\n",
    "                                  max_examples=None,\n",
    "                                  tokenizer_name=\"tiktoken/gpt2\")\n",
    "    \n",
    "    trainer = SFTTrainer(cfg, device, model, train_ds, test_ds)\n",
    "    trainer.fit()\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option('--pretrain', '-p', default=\"huggingface\")\n",
    "@click.option('--batch-size', '-b', default=1)\n",
    "@click.option('--exp-name', '-n', default=\"default\")\n",
    "def main(pretrain, batch_size, exp_name):\n",
    "    torch.manual_seed(1234)\n",
    "    train(pretrain, batch_size, exp_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T07:22:52.453108700Z",
     "start_time": "2023-12-04T07:22:50.101142100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n733f84SQuN"
   },
   "source": [
    "Execute the following cell for each kernel restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAaXV7HHD2Pp"
   },
   "source": [
    "# 新段落"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
